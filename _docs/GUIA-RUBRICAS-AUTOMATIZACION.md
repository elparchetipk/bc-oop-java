# üìä R√∫bricas de Evaluaci√≥n Automatizada - Bootcamp POO Java

## üìÅ Estructura de Archivos

Cada semana del bootcamp tiene 3 formatos de r√∫brica:

```
bootcamp/
‚îú‚îÄ‚îÄ semana-00/
‚îÇ   ‚îú‚îÄ‚îÄ RUBRICA_EVALUACION.md          # Formato legible para estudiantes
‚îÇ   ‚îú‚îÄ‚îÄ rubrica_evaluacion.json        # Para scripts de automatizaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ rubrica_evaluacion.yaml        # Formato alternativo
‚îú‚îÄ‚îÄ semana-01/
‚îÇ   ‚îú‚îÄ‚îÄ RUBRICA_EVALUACION.md
‚îÇ   ‚îú‚îÄ‚îÄ rubrica_evaluacion.json
‚îÇ   ‚îî‚îÄ‚îÄ rubrica_evaluacion.yaml
‚îú‚îÄ‚îÄ semana-02/
‚îÇ   ‚îú‚îÄ‚îÄ RUBRICA_EVALUACION.md
‚îÇ   ‚îú‚îÄ‚îÄ rubrica_evaluacion.json
‚îÇ   ‚îî‚îÄ‚îÄ rubrica_evaluacion.yaml
‚îî‚îÄ‚îÄ semana-03/
    ‚îú‚îÄ‚îÄ RUBRICA_EVALUACION.md
    ‚îú‚îÄ‚îÄ rubrica_evaluacion.json
    ‚îî‚îÄ‚îÄ rubrica_evaluacion.yaml
```

---

## üéØ Prop√≥sito de los Archivos

### üìÑ `RUBRICA_EVALUACION.md`
- **Formato:** Markdown legible
- **Audiencia:** Estudiantes e instructores
- **Uso:** Consulta manual, gu√≠a de aprendizaje
- **Contenido:** R√∫bricas detalladas con tablas y descripciones

### üîß `rubrica_evaluacion.json`
- **Formato:** JSON estructurado
- **Audiencia:** Scripts de automatizaci√≥n
- **Uso:** Entrada para scripts Python que eval√∫an repositorios
- **Contenido:** Criterios de evaluaci√≥n, patrones de validaci√≥n, configuraci√≥n de API

### üìã `rubrica_evaluacion.yaml`
- **Formato:** YAML legible y estructurado
- **Audiencia:** Scripts de automatizaci√≥n (m√°s legible que JSON)
- **Uso:** Alternativa a JSON, f√°cil de editar manualmente
- **Contenido:** Misma informaci√≥n que JSON pero m√°s legible

---

## ü§ñ Uso con Scripts de Python + Claude API

### Estructura General de Datos

Cada archivo JSON/YAML contiene:

```json
{
  "semana": "01",
  "titulo": "Introducci√≥n al Paradigma Orientado a Objetos",
  "descripcion": "...",
  "nota_minima_aprobatoria": 3.0,
  "distribucion_evaluacion": {
    "conocimiento": {"peso": 30},
    "desempeno": {"peso": 40},
    "producto": {"peso": 30}
  },
  "evidencias": {
    "conocimiento": [...],
    "desempeno": [...],
    "producto": [...]
  },
  "configuracion_script_automatizacion": {
    "lenguaje": "python",
    "api": "claude",
    "prompts_claude": {...},
    "validaciones": {...}
  }
}
```

---

## üêç Integraci√≥n con Python

### Ejemplo de Carga de R√∫brica

```python
import json
import yaml
from pathlib import Path

# Opci√≥n 1: Cargar JSON
def load_rubric_json(semana: str):
    rubric_path = Path(f"bootcamp/semana-{semana}/rubrica_evaluacion.json")
    with open(rubric_path, 'r', encoding='utf-8') as f:
        return json.load(f)

# Opci√≥n 2: Cargar YAML (m√°s legible)
def load_rubric_yaml(semana: str):
    rubric_path = Path(f"bootcamp/semana-{semana}/rubrica_evaluacion.yaml")
    with open(rubric_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

# Uso
rubrica = load_rubric_json("01")
print(f"Evaluando: {rubrica['titulo']}")
```

### Ejemplo de Validaci√≥n Automatizada

```python
import re
from typing import Dict, List

class ValidadorCodigo:
    def __init__(self, rubrica: Dict):
        self.rubrica = rubrica
    
    def validar_ejercicio(self, codigo: str, ejercicio_id: str) -> Dict:
        """
        Valida c√≥digo contra criterios de un ejercicio espec√≠fico
        """
        ejercicio = self._buscar_ejercicio(ejercicio_id)
        validacion = ejercicio.get('validacion_automatica', {})
        
        resultados = {
            'compilacion': self._verificar_compilacion(codigo),
            'clases': self._verificar_clases(codigo, validacion),
            'metodos': self._verificar_metodos(codigo, validacion),
            'patrones': self._verificar_patrones(codigo, validacion)
        }
        
        return resultados
    
    def _verificar_patrones(self, codigo: str, validacion: Dict) -> bool:
        """Verifica patrones regex definidos en la r√∫brica"""
        if 'patron_codigo' in validacion:
            patron = validacion['patron_codigo']
            return bool(re.search(patron, codigo))
        return True
    
    def _verificar_clases(self, codigo: str, validacion: Dict) -> List[str]:
        """Extrae clases encontradas en el c√≥digo"""
        patron_clase = r'class\s+(\w+)'
        return re.findall(patron_clase, codigo)
```

### Ejemplo con Claude API

```python
import anthropic
import os

class EvaluadorConClaude:
    def __init__(self, rubrica: Dict):
        self.rubrica = rubrica
        self.client = anthropic.Anthropic(
            api_key=os.environ.get("CLAUDE_API_KEY")
        )
    
    def evaluar_codigo(self, codigo: str, tipo_evidencia: str) -> Dict:
        """
        Eval√∫a c√≥digo usando Claude seg√∫n prompts de la r√∫brica
        """
        config = self.rubrica['configuracion_script_automatizacion']
        prompts = config.get('prompts_claude', {})
        
        # Seleccionar prompt seg√∫n tipo de evidencia
        prompt_key = f"evaluar_{tipo_evidencia}"
        prompt_template = prompts.get(prompt_key, "")
        
        # Construir prompt completo
        prompt_completo = f"""
{prompt_template}

C√≥digo a evaluar:
```java
{codigo}
```

R√∫brica:
{self._extraer_criterios_relevantes(tipo_evidencia)}

Proporciona:
1. Puntuaci√≥n (0-5.0)
2. Fortalezas identificadas
3. √Åreas de mejora
4. Comentarios espec√≠ficos
"""
        
        # Llamar a Claude
        message = self.client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=2000,
            messages=[
                {"role": "user", "content": prompt_completo}
            ]
        )
        
        return self._parsear_respuesta(message.content)
    
    def _extraer_criterios_relevantes(self, tipo: str) -> str:
        """Extrae criterios de evaluaci√≥n relevantes de la r√∫brica"""
        evidencias = self.rubrica['evidencias'].get(tipo, [])
        return json.dumps(evidencias, indent=2, ensure_ascii=False)
```

---

## üîç Validaciones Automatizables

### 1. Validaciones Est√°ticas (Sin Claude)

Estas se pueden hacer con an√°lisis de c√≥digo:

```python
validaciones = {
    "debe_compilar": True,                    # javac
    "debe_ejecutar": True,                    # java
    "minimo_clases": 2,                       # regex
    "minimo_metodos": 3,                      # regex
    "minimo_atributos": 4,                    # regex
    "patron_getter": "public.*get[A-Z].*",   # regex
    "patron_setter": "public void set.*",     # regex
    "todos_privados": True,                   # regex
    "uso_arrays": True,                       # regex
    "patron_scanner": "Scanner|import.*Scanner" # regex
}
```

### 2. Validaciones con Claude API

Estas requieren an√°lisis sem√°ntico:

```python
prompts_claude = {
    "evaluar_encapsulacion": "Analiza si aplica correctamente encapsulaci√≥n...",
    "evaluar_modelado": "Eval√∫a si las clases modelan apropiadamente el dominio...",
    "evaluar_codigo": "Analiza calidad, sintaxis y uso de POO...",
    "evaluar_documentacion": "Revisa comentarios Javadoc y README..."
}
```

---

## üìä Estructura de Respuesta del Script

```json
{
  "estudiante": "Juan P√©rez",
  "semana": "01",
  "repositorio": "https://github.com/juanperez/semana-01",
  "fecha_evaluacion": "2025-10-21T20:30:00",
  "resultados": {
    "conocimiento": {
      "puntuacion": 4.2,
      "peso": 30,
      "evidencias": [
        {
          "id": "C1",
          "nombre": "Cuestionario Te√≥rico",
          "puntuacion": 4.5,
          "comentarios": "Excelente comprensi√≥n de conceptos..."
        }
      ]
    },
    "desempeno": {
      "puntuacion": 4.0,
      "peso": 40,
      "evidencias": [...]
    },
    "producto": {
      "puntuacion": 3.8,
      "peso": 30,
      "evidencias": [...]
    }
  },
  "nota_final": 4.0,
  "aprobado": true,
  "feedback_general": "...",
  "validaciones_automaticas": {
    "compilacion": true,
    "ejecucion": true,
    "estilo_codigo": true,
    "cobertura_requisitos": 85
  }
}
```

---

## üöÄ Flujo de Evaluaci√≥n Recomendado

```
1. Clonar repositorio del estudiante
   ‚îî‚îÄ> git clone <repo_url>

2. Cargar r√∫brica de la semana
   ‚îî‚îÄ> rubrica = load_rubric_json("01")

3. Validaciones est√°ticas
   ‚îú‚îÄ> Compilar c√≥digo (javac)
   ‚îú‚îÄ> Ejecutar pruebas (java)
   ‚îú‚îÄ> Verificar patrones regex
   ‚îî‚îÄ> An√°lisis est√°tico (checkstyle, opcional)

4. Validaciones con Claude API
   ‚îú‚îÄ> Evaluar calidad de c√≥digo
   ‚îú‚îÄ> Analizar encapsulaci√≥n
   ‚îú‚îÄ> Revisar documentaci√≥n
   ‚îî‚îÄ> Evaluar modelado del dominio

5. Calcular puntuaci√≥n final
   ‚îî‚îÄ> Aplicar pesos de distribuci√≥n_evaluacion

6. Generar reporte
   ‚îî‚îÄ> JSON, PDF o HTML con resultados
```

---

## üõ†Ô∏è Herramientas Complementarias

### Compilaci√≥n Java

```python
import subprocess

def compilar_java(archivo: str) -> tuple[bool, str]:
    """Compila archivo Java y retorna (√©xito, mensaje)"""
    resultado = subprocess.run(
        ['javac', archivo],
        capture_output=True,
        text=True
    )
    return resultado.returncode == 0, resultado.stderr

def ejecutar_java(clase: str) -> tuple[bool, str]:
    """Ejecuta clase Java y retorna (√©xito, output)"""
    resultado = subprocess.run(
        ['java', clase],
        capture_output=True,
        text=True,
        timeout=10
    )
    return resultado.returncode == 0, resultado.stdout
```

### An√°lisis de C√≥digo

```python
import javalang

def analizar_estructura(codigo: str) -> Dict:
    """Analiza estructura del c√≥digo Java"""
    try:
        tree = javalang.parse.parse(codigo)
        
        clases = [c.name for c in tree.types if isinstance(c, javalang.tree.ClassDeclaration)]
        metodos = []
        atributos = []
        
        for path, node in tree:
            if isinstance(node, javalang.tree.MethodDeclaration):
                metodos.append(node.name)
            elif isinstance(node, javalang.tree.FieldDeclaration):
                for declarator in node.declarators:
                    atributos.append(declarator.name)
        
        return {
            'clases': clases,
            'metodos': metodos,
            'atributos': atributos,
            'num_clases': len(clases),
            'num_metodos': len(metodos),
            'num_atributos': len(atributos)
        }
    except Exception as e:
        return {'error': str(e)}
```

---

## üìù Ejemplo Completo de Script

Ver archivo: `_scripts/evaluador_automatico.py` (pr√≥ximamente)

Caracter√≠sticas:
- ‚úÖ Carga r√∫bricas JSON/YAML
- ‚úÖ Clona repositorios de GitHub
- ‚úÖ Compila y ejecuta c√≥digo Java
- ‚úÖ Valida con patrones regex
- ‚úÖ Eval√∫a con Claude API
- ‚úÖ Genera reportes detallados
- ‚úÖ Env√≠a feedback por email/GitHub Issues

---

## üîê Variables de Entorno Requeridas

```bash
# .env
CLAUDE_API_KEY=sk-ant-api03-...
GITHUB_TOKEN=ghp_...
JAVA_HOME=/usr/lib/jvm/java-17-openjdk
```

---

## üì¶ Dependencias Python

```txt
# requirements.txt
anthropic>=0.25.0
pyyaml>=6.0
javalang>=0.13.0
gitpython>=3.1.0
python-dotenv>=1.0.0
```

---

## ‚ö†Ô∏è Consideraciones Importantes

1. **Privacidad**: Nunca incluir credenciales en los archivos de r√∫brica
2. **Costos API**: Claude API tiene costos por token, monitorear uso
3. **Timeouts**: Establecer timeouts para compilaci√≥n/ejecuci√≥n (30-60s)
4. **Sandbox**: Ejecutar c√≥digo estudiantil en entorno aislado
5. **Feedback**: Generar retroalimentaci√≥n constructiva, no solo puntuaciones

---

## üìû Soporte

Para dudas sobre las r√∫bricas o el sistema de evaluaci√≥n:
- Revisar documentaci√≥n en `_docs/`
- Consultar con instructor del bootcamp
- Abrir issue en el repositorio

---

**√öltima actualizaci√≥n:** 21 de octubre de 2025  
**Versi√≥n:** 1.0.0  
**Bootcamp:** POO Java - SENA 2025
